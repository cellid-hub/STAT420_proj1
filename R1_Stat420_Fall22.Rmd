---
title: "Hierarchical Models, CLT and Delta Method"
author: "[ADD NAME (ID)], Matthew Foulk (116992152)"
output:
  pdf_document:
    toc: yes
  html_document:
    number_sections: yes    
    toc: yes
editor_options: 
  markdown: 
    wrap: 72
---

# Hierarchical Models

Consider the following hierarchical model:

$$ T \sim \text{Gamma}(\alpha = 10, \beta = 4), \quad Y|T \sim \text{Pois}(T)$$
Write a function that models the random variable $Y$. This function must
take input values $\alpha$ and $\beta$ and output the value that the
random variable will take on a single run of the experiment.

```{r}
poisson_gamma <- function(alpha, beta){
  T <- rgamma(n = 1, shape = alpha, scale = beta)
  Y <- rpois(n = 1, lambda = T)
}
```

Use the replicate function to get 10000 values of the random variable
$Y$. Store these values in a variable 'y_empirical'.

```{r}
y_empirical <- replicate(10000,poisson_gamma(10,4))
```

Use the 'hist' function to calculate the empirical distribution of $Y$.

```{r}
hist(y_empirical)
```

Now get 10000 random values from the appropriate negative binomial
distribution, and store these in the variable 'y_theoretical'. Use the
'qqplot' function to compare the quantiles of 'y_empirical' to those of
'y_theoretical'. What do you notice?

```{r}
y_theoretical <- replicate(10000,rnbinom(n = 1,size = 10, prob = 1/(1+4))) 
par(mfrow = c(1,2))
hist(y_theoretical)
qqplot(y_theoretical,y_empirical)
```
Answer:  
The Q-Q plot creates a roughly straight line. This likely indicates that the poisson-gamma mixture can be viewed as a negative binomial distribution.

# Limiting Distributions

## Maximum of Uniforms

Write a function 'uni_sample_max' that simulates the 'sample_max'
statistic on a random sample of size $n$ coming from the uniform
distribution on $(0, 1)$. Note that this function takes input $n$, the
sample size.

```{r}
uni_sample_max <- function(n){
  unif <- runif(n)
  sample_max <- max(unif)
}
```

Use the above function define the statistic:
$$ \hat{\theta} = n(1-X_{(n)}) $$ We know that this statistic converges
in distribution to $\text{Exp}(\lambda = 1)$. Call the function
'theta_hat' which must take input $n$, the sample size of the uniform
random sample.

```{r}
theta_hat <- function(n){
  t_hat <- n*(1-uni_sample_max(n))
}
```

Write a function \`theta_hat_plot' which takes input $n$, and outputs
the qqplot of 10000 values coming from the replicates of 'theta_hat' and
10000 values coming from the $\text{Exp}(\lambda = 1)$ (use the 'rexp'
command for the latter).

```{r}
theta_hat_plot <- function(n){
  t_hat_sample <- replicate(10000, theta_hat(n))
  exp <- rexp(10000)
  qqplot(t_hat_sample, exp, main=paste("Q-Q: n=",n))
}
```

Evaluate 'theta_hat_plot' on values of $n$ in the vector
$(1, 2, 3, 5, 10, 20, 40, 50, 100, 1000)$.

```{r}
ns <- c(1, 2, 3, 5, 10, 20, 40, 50, 100, 1000)
for (n in ns){
  theta_hat_plot(n)
}

```

# Delta Method

## Odds for Binomial Distribution

Consider the estimator $\hat{\theta} = \frac{\hat{p}}{1-\hat{p}}$,
(where $\hat{p}$ is proportion of successes in $n$ Bernoulli trials) for
the parameter 'odds' $\theta = \frac{p}{1-p}$. Let
$g(p) = \frac{p}{1-p}$, then using the delta-method we know that
$$ \sqrt{n}(g(\hat(p)) - g(p)) \longrightarrow N(0, \sigma^2(g'(p))^2) $$

Write a function 'odds_hat' that takes input the sample size $n$, and
calculates the odds estimate for $n$ independent Bernoulli random
variable with $p=0.7$.

```{r}
odds_hat <- function(n){
  x <- rbinom(n, 1, .7)
  p_hat <- mean(x)
  odds <- p_hat/(1-p_hat)
  return(odds)
}

```

Write a function \`odds_plot' which takes input $n$, and outputs the
qqplot of 10000 values coming from the replicates of 'odds_hat' and
10000 values coming from the $N(0, \sigma^2(g'(0.7))^2)$ (use the
'rnorm' command for the latter).

```{r}
odds_plot <- function(n){
  sample_odds = replicate(10000, odds_hat(n))
  var = (1/(1-.7)^2)^2
  dist_odds = rnorm(10000, 0, var)
  qqplot(sample_odds, dist_odds, main=paste("Q-Q: n=",n))
}

```

Evaluate 'odds_plot' on values of $n$ in the vector
$(1, 2, 3, 5, 10, 20, 40, 50, 100, 1000)$.

```{r}
ns <- c(1, 2, 3, 5, 10, 20, 40, 50, 100, 1000)
for (n in ns){
  odds_plot(n)
}

```

## Approximating $\frac{1}{\mu}$.

Consider sampling from $\text{Gamma}(\alpha =2, \beta = 4)$. Run a
simulation (like the one for 'odds') to show the following property of
the limiting distribution of the reciprocal of the sample mean

$$ \frac{\sqrt{n}\left(\frac{1}{\overline{X}} - \frac{1}{\mu}\right)}{\frac{1}{\overline{X}^2} S} \longrightarrow N(0,1)$$
where $\overline{X}$ is the sample mean, and $S = \sqrt{S^2}$.

```{r}
normal_approx <- function(n){
  samp = rgamma(n, shape=2, scale=4)
  samp_mean = mean(samp)
  variance = var(samp)
  output <- sqrt(n)*(1/samp_mean - 1/8)/(sqrt(variance)/samp_mean^2)
  return(output)
}

```

```{r}
gamma_plot <- function(n){
  sample = replicate(10000, normal_approx(n))
  dist_odds = rnorm(10000, 0, 1)
  qqplot(sample, dist_odds, main=paste("Q-Q: n=",n))
}
```

```{r}
ns <- c(1, 2, 3, 5, 10, 20, 40, 50, 100, 1000)
for (n in ns){
  gamma_plot(n)
}

```

